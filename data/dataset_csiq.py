import os
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import random
from PIL import Image, ImageEnhance, ImageFilter
import numpy as np
import io
import matplotlib.pyplot as plt

class CSIQDataset(Dataset):
    def __init__(self, root: str, phase: str = "train", crop_size: int = 224, dataset_type="synthetic"):
        """
        dataset_type: 
            "synthetic" (CSIQ) â†’ Hard Negative ì ìš©
            "authentic" (KonIQ-10k, SPAQ, LIVE-FB) â†’ Hard Negative ì ìš© ì•ˆí•¨
        """
        super().__init__()
        self.root = str(root)
        self.phase = phase
        self.crop_size = crop_size
        self.dataset_type = dataset_type  # âœ… ë°ì´í„°ì…‹ ìœ í˜• ê²°ì •

        # âœ… CSIQ ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •
        scores_txt_path = os.path.join(self.root, "CSIQ.txt")
        if not os.path.isfile(scores_txt_path):
            raise FileNotFoundError(f"CSIQ TXT íŒŒì¼ì´ {scores_txt_path} ê²½ë¡œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # âœ… CSV íŒŒì¼ ë¡œë“œ (êµ¬ë¶„ì `,` ì‚¬ìš©)
        scores_data = pd.read_csv(scores_txt_path, sep=',', names=["dist_img", "dist_type", "ref_img", "mos"], header=0)

        # ğŸ”¹ NaN ê°’ ì œê±° í›„ ë¬¸ìì—´ë¡œ ë³€í™˜
        scores_data.dropna(inplace=True)
        scores_data = scores_data.astype(str)

        # âœ… ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
        self.image_paths = [os.path.join(self.root, img_path.replace("CSIQ/", "")) for img_path in scores_data["dist_img"]]
        self.reference_paths = [os.path.join(self.root, img_path.replace("CSIQ/", "")) for img_path in scores_data["ref_img"]]
        self.mos = scores_data["mos"].astype(float).values  # MOS ê°’ì„ floatë¡œ ë³€í™˜

        # âœ… CSIQ ë°ì´í„°ì…‹ì˜ 6ê°œ ì™œê³¡ ìœ í˜• (Hard Negative ì ìš© ëŒ€ìƒ)
        self.distortion_types = ["jpeg", "jpeg2000", "blur", "awgn", "contrast", "fnoise"]

    def transform(self, image: Image) -> torch.Tensor:
        return transforms.Compose([
            transforms.Resize((self.crop_size, self.crop_size)),
            transforms.ToTensor(),
        ])(image)

    def apply_distortion(self, image, distortion, level):
        try:
            image = image.convert("RGB")  # Ensure the image is in RGB format

            if distortion == "jpeg":
                quality = max(1, min(100, int(100 - (level * 100))))
                buffer = io.BytesIO()
                image.save(buffer, format="JPEG", quality=quality)
                buffer.seek(0)
                return Image.open(buffer)

            elif distortion == "jpeg2000":
                image = image.resize((image.width // 2, image.height // 2)).resize((image.width, image.height))

            elif distortion == "blur":
                image = image.filter(ImageFilter.GaussianBlur(radius=level))

            elif distortion == "awgn":
                image_array = np.array(image, dtype=np.float32)
                noise = np.random.normal(loc=0, scale=level * 255, size=image_array.shape).astype(np.float32)
                noisy_image = image_array + noise
                noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)
                image = Image.fromarray(noisy_image)

            elif distortion == "contrast":
                enhancer = ImageEnhance.Contrast(image)
                image = enhancer.enhance(1 + level)

            elif distortion == "fnoise":
                image_array = np.array(image).astype(np.float32)
                noise = np.random.normal(1, level, image_array.shape)
                noisy_image = image_array * noise
                noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)
                image = Image.fromarray(noisy_image)

            else:
                print(f"[Warning] Distortion type '{distortion}' not implemented.")

        except Exception as e:
            print(f"[Error] Applying distortion {distortion} with level {level}: {e}")

        return image

    def __getitem__(self, index: int):
        """
        âœ… ë°ì´í„°ì…‹ ìœ í˜•ì— ë”°ë¼ `img_B` ì²˜ë¦¬ ë°©ì‹ ë³€ê²½ âœ…
        - Synthetic ë°ì´í„°ì…‹(CSIQ) â†’ Hard Negative ì ìš©
        - Authentic ë°ì´í„°ì…‹(KonIQ-10k, SPAQ, LIVE-FB) â†’ Hard Negative ì ìš© ì•ˆí•¨
        """
        img_A = Image.open(self.image_paths[index]).convert("RGB")  
        img_B = Image.open(self.reference_paths[index]).convert("RGB")  

        # âœ… Synthetic ë°ì´í„°ì…‹ì—ë§Œ Hard Negative ì ìš©
        if self.dataset_type == "synthetic":
            distortion_type = random.choice(self.distortion_types)
            level = random.uniform(0.1, 0.5)
            img_B = self.apply_distortion(img_B, distortion_type, level)

        img_A = self.transform(img_A)
        img_B = self.transform(img_B)

        return {
            "img_A": img_A,
            "img_B": img_B,
            "mos": torch.tensor(self.mos[index], dtype=torch.float32),
        }

    def __len__(self):
        return len(self.image_paths)


if __name__ == "__main__":
    """
    âœ… Hard Negative ì ìš© ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³ , ì´ë¯¸ì§€ ë¹„êµë¥¼ ìˆ˜í–‰
    """
    dataset_path = "E:/ARNIQA - SE - mix/ARNIQA/dataset/CSIQ"

    synthetic_dataset = CSIQDataset(root=dataset_path, phase="train", crop_size=224, dataset_type="synthetic")
    synthetic_dataloader = DataLoader(synthetic_dataset, batch_size=4, shuffle=True)

    print(f"Synthetic Dataset size: {len(synthetic_dataset)}")

    # âœ… Hard Negative ì ìš© í™•ì¸
    sample_batch_synthetic = next(iter(synthetic_dataloader))
    print(f"\n[Synthetic] Hard Negative ì ìš© í™•ì¸:")
    for i in range(4):  
        print(f"  Sample {i+1} - MOS: {sample_batch_synthetic['mos'][i]}")

    # âœ… ì›ë³¸ ì´ë¯¸ì§€ vs Hard Negative ë¹„êµ
    sample_index = 0
    img_A_np = sample_batch_synthetic['img_A'][sample_index].permute(1, 2, 0).numpy()
    img_B_np = sample_batch_synthetic['img_B'][sample_index].permute(1, 2, 0).numpy()

    fig, ax = plt.subplots(1, 2, figsize=(10, 5))
    ax[0].imshow(img_A_np)
    ax[0].set_title("Distorted Image (img_A)")
    ax[1].imshow(img_B_np)
    ax[1].set_title("Hard Negative (img_B)")
    plt.show()
