# ÏõêÎ≥∏
""" 
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_spaq import SPAQDataset
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config

# ‚úÖ ÏÜêÏã§ Ìï®Ïàò (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# ‚úÖ SROCC Î∞è PLCC Í≥ÑÏÇ∞
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# ‚úÖ ÌïôÏäµ Î£®ÌîÑ
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # ‚úÖ Î™®Îç∏ ÏòàÏ∏°
            preds = model(img_A)

            # ‚úÖ ÏÜêÏã§ Ìï®Ïàò Í≥ÑÏÇ∞
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # ‚úÖ Í≤ÄÏ¶ù
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # ‚úÖ Î™®Îç∏ Ï†ÄÏû•
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nüîπ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")

        lr_scheduler.step()

    print("\n‚úÖ **Training Completed** ‚úÖ")

    return {
        "loss": train_losses,
        "srocc": val_srocc_values,
        "plcc": val_plcc_values
    }

# ‚úÖ Í≤ÄÏ¶ù Î£®ÌîÑ
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# ‚úÖ ÌÖåÏä§Ìä∏ Î£®ÌîÑ (Ï∂îÍ∞Ä)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": srocc_values,
        "plcc": plcc_values
    }

# ‚úÖ Î™®Îç∏ Ï†ÄÏû• Ìï®Ïàò
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)



# ‚úÖ Î©îÏù∏ Ïã§Ìñâ
if __name__ == "__main__":
    # ‚úÖ ÏÑ§Ï†ï ÌååÏùº Î°úÎìú
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # ‚úÖ GPU ÏÑ§Ï†ï
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    # ‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú
    dataset_path = Path(args.data_base_path)
    dataset = SPAQDataset(str(dataset_path), crop_size=224)


    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    # ‚úÖ Î™®Îç∏ ÏÉùÏÑ±
    model = EnhancedDistortionDetectionModel().to(device)

    # ‚úÖ ÏòµÌã∞ÎßàÏù¥Ï†Ä Î∞è Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # ‚úÖ ÌïôÏäµ ÏãúÏûë
    train_metrics = train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)

    # ‚úÖ ÌÖåÏä§Ìä∏ ÏàòÌñâ
    test_metrics = test(model, test_dataloader, device)

    # ‚úÖ ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•
    print("\n‚úÖ **Training Completed** ‚úÖ\n")

    print("üîπ **Final Training Metrics:** üîπ")
    for epoch, (loss, srocc, plcc) in enumerate(zip(train_metrics["loss"], train_metrics["srocc"], train_metrics["plcc"])):
        print(f"üìå **Epoch {epoch+1}:** Loss: {loss:.6f}, SROCC: {srocc:.6f}, PLCC: {plcc:.6f}")

    print("\nüîπ **Final Validation Metrics:** üîπ", {
        "srocc": train_metrics["srocc"],
        "plcc": train_metrics["plcc"]
    })

    print("üîπ **Final Test Metrics:** üîπ", test_metrics)
 """

# hmm
""" 
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_clive import CLIVEDataset
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config


# ‚úÖ ÏÜêÏã§ Ìï®Ïàò (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss


# ‚úÖ SROCC Î∞è PLCC Í≥ÑÏÇ∞
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc


# ‚úÖ ÌÖåÏä§Ìä∏ Î£®ÌîÑ (ÏóêÌè¨ÌÅ¨Î≥ÑÎ°ú SROCC, PLCC Ï†ÄÏû•)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)


# ‚úÖ ÌïôÏäµ Î£®ÌîÑ (Í∞Å epoch ÌõÑ test() Ïã§Ìñâ)
def train(args, model, train_dataloader, val_dataloader, test_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []
    test_srocc_values, test_plcc_values = [], []  # ‚úÖ Test Í≤∞Í≥º Ï†ÄÏû•

    for epoch in range(args["training"]["epochs"]):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args['training']['epochs']}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # ‚úÖ Î™®Îç∏ ÏòàÏ∏°
            preds = model(img_A)

            # ‚úÖ ÏÜêÏã§ Ìï®Ïàò Í≥ÑÏÇ∞
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # ‚úÖ Í≤ÄÏ¶ù
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # ‚úÖ ÌÖåÏä§Ìä∏ (Í∞Å epoch ÌõÑ Ïã§Ìñâ)
        test_srocc, test_plcc = test(model, test_dataloader, device)
        test_srocc_values.append(test_srocc)
        test_plcc_values.append(test_plcc)

        # ‚úÖ Î™®Îç∏ Ï†ÄÏû•
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args["checkpoint_base_path"], epoch, val_srocc)

        print(f"\nüîπ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}, "
              f"Test SROCC: {test_srocc:.6f}, Test PLCC: {test_plcc:.6f}")

        lr_scheduler.step()

    print("\n‚úÖ **Training Completed** ‚úÖ")

    return {
        "loss": train_losses,
        "val_srocc": val_srocc_values,
        "val_plcc": val_plcc_values,
        "test_srocc": test_srocc_values,  # ‚úÖ Test Í≤∞Í≥º Ï∂îÍ∞Ä Ï†ÄÏû•
        "test_plcc": test_plcc_values
    }




# ‚úÖ Í≤ÄÏ¶ù Î£®ÌîÑ
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)


# ‚úÖ Î™®Îç∏ Ï†ÄÏû• Ìï®Ïàò
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)


# ‚úÖ Î©îÏù∏ Ïã§Ìñâ
if __name__ == "__main__":
    # ‚úÖ ÏÑ§Ï†ï ÌååÏùº Î°úÎìú
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # ‚úÖ GPU ÏÑ§Ï†ï
    device = torch.device(f"cuda:{args['device']}" if torch.cuda.is_available() else "cpu")

    # ‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú
    dataset_path = Path(args["data_base_path"])
    dataset = CLIVEDataset(str(dataset_path), crop_size=224)

    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args["training"]["batch_size"], shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args["training"]["batch_size"], shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args["training"]["batch_size"], shuffle=False, num_workers=4)

    # ‚úÖ Î™®Îç∏ ÏÉùÏÑ±
    model = EnhancedDistortionDetectionModel().to(device)

    # ‚úÖ ÏòµÌã∞ÎßàÏù¥Ï†Ä Î∞è Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï
    optimizer = optim.SGD(model.parameters(), lr=args["training"]["learning_rate"], momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # ‚úÖ ÌïôÏäµ ÏãúÏûë
    train_metrics = train(args, model, train_dataloader, val_dataloader, test_dataloader, optimizer, lr_scheduler, device)

    # ‚úÖ ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•
    print("\n‚úÖ **Training Completed** ‚úÖ\n")

    print("üîπ **Final Training Metrics:** üîπ")
    for epoch, (loss, val_srocc, val_plcc, test_srocc, test_plcc) in enumerate(
            zip(train_metrics["loss"], train_metrics["val_srocc"], train_metrics["val_plcc"], train_metrics["test_srocc"], train_metrics["test_plcc"])):
        print(f"üìå **Epoch {epoch+1}:** Loss: {loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}, "
              f"Test SROCC: {test_srocc:.6f}, Test PLCC: {test_plcc:.6f}")

    print("\nüîπ **Final Validation Metrics:** üîπ", {
        "srocc": train_metrics["val_srocc"],
        "plcc": train_metrics["val_plcc"]
    })

    print("\nüîπ **Final Test Metrics:** üîπ", {
        "srocc": train_metrics["test_srocc"],
        "plcc": train_metrics["test_plcc"]
    })

 """

# HAN_IQA_PLUS
""" import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_koniq10k import KONIQ10KDataset
from models.attention_se import HAN_IQA_PLUS  # üî• Î™®Îç∏ Î≥ÄÍ≤Ω
from utils.utils import load_config

# ‚úÖ ÏÜêÏã§ Ìï®Ïàò (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))  # L1 Loss
    return mse_loss + 0.1 * perceptual_loss  # üî• Perceptual Loss Î∞òÏòÅ

# ‚úÖ SROCC Î∞è PLCC Í≥ÑÏÇ∞
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# ‚úÖ ÌïôÏäµ Î£®ÌîÑ
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # ‚úÖ Î™®Îç∏ ÏòàÏ∏°
            preds = model(img_A)

            # ‚úÖ ÏÜêÏã§ Ìï®Ïàò Í≥ÑÏÇ∞
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # ‚úÖ Í≤ÄÏ¶ù
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # ‚úÖ Î™®Îç∏ Ï†ÄÏû•
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nüîπ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")

        lr_scheduler.step()

    print("\n‚úÖ **Training Completed** ‚úÖ")

    return {
        "loss": train_losses,
        "srocc": val_srocc_values,
        "plcc": val_plcc_values
    }

# ‚úÖ Í≤ÄÏ¶ù Î£®ÌîÑ
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# ‚úÖ ÌÖåÏä§Ìä∏ Î£®ÌîÑ (Ï∂îÍ∞Ä)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": srocc_values,
        "plcc": plcc_values
    }

# ‚úÖ Î™®Îç∏ Ï†ÄÏû• Ìï®Ïàò
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)

# ‚úÖ Î©îÏù∏ Ïã§Ìñâ
if __name__ == "__main__":
    # ‚úÖ ÏÑ§Ï†ï ÌååÏùº Î°úÎìú
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # ‚úÖ GPU ÏÑ§Ï†ï
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    # ‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú
    dataset_path = Path(args.data_base_path)
    dataset = KONIQ10KDataset(str(dataset_path), crop_size=224)

    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    # ‚úÖ Î™®Îç∏ ÏÉùÏÑ±
    model = HAN_IQA_PLUS().to(device)  # üî• ÏÉàÎ°úÏö¥ Î™®Îç∏ Ï†ÅÏö©

    # ‚úÖ ÏòµÌã∞ÎßàÏù¥Ï†Ä Î∞è Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # ‚úÖ ÌïôÏäµ ÏãúÏûë
    train_metrics = train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)

    # ‚úÖ ÌÖåÏä§Ìä∏ ÏàòÌñâ
    test_metrics = test(model, test_dataloader, device)

    # ‚úÖ ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•
    print("\n‚úÖ **Training Completed** ‚úÖ\n")

    print("üîπ **Final Training Metrics:** üîπ")
    for epoch, (loss, srocc, plcc) in enumerate(zip(train_metrics["loss"], train_metrics["srocc"], train_metrics["plcc"])):
        print(f"üìå **Epoch {epoch+1}:** Loss: {loss:.6f}, SROCC: {srocc:.6f}, PLCC: {plcc:.6f}")

    print("\nüîπ **Final Validation Metrics:** üîπ", {
        "srocc": train_metrics["srocc"],
        "plcc": train_metrics["plcc"]
    })

    print("üîπ **Final Test Metrics:** üîπ", test_metrics) """





# ÏãúÍ∞ÅÌôî1
""" import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
from scipy import stats
from models.attention_se import EnhancedDistortionDetectionModel
from data.dataset_kadid10k import KADID10KDataset
from utils.utils import load_config
from grad_cam import GradCAM

# ‚úÖ ÏÜêÏã§ Ìï®Ïàò (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# ‚úÖ SROCC Î∞è PLCC Í≥ÑÏÇ∞
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# ‚úÖ Î™®Îç∏ Ï†ÄÏû• Ìï®Ïàò
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)

# ‚úÖ Feature Map ÏãúÍ∞ÅÌôî
def visualize_feature_maps(model, dataloader, device):
    model.eval()
    batch = next(iter(dataloader))
    img_A = batch["img_A"].to(device)

    with torch.no_grad():
        feat1, feat2, feat3, feat4, feat5 = model.vgg(img_A)
        cpfe_output = model.cpfe(feat5)
        hnca_output = model.hnca(cpfe_output)

    feature_maps = {
        "VGG_feat1": feat1,
        "VGG_feat2": feat2,
        "VGG_feat3": feat3,
        "VGG_feat4": feat4,
        "VGG_feat5": feat5,
        "CPFE_output": cpfe_output,
        "HNCA_output": hnca_output
    }

    for name, fmap in feature_maps.items():
        fmap = fmap[0].cpu().numpy()
        fmap = np.mean(fmap, axis=0)  # Ï±ÑÎÑê ÌèâÍ∑†
        plt.imshow(fmap, cmap='jet')
        plt.axis('off')
        plt.title(name)
        plt.savefig(f"results/{name}.png")
        plt.close()

# ‚úÖ ÌïôÏäµ Î£®ÌîÑ
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()
            preds = model(img_A)

            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        val_srocc, val_plcc = validate(model, val_dataloader, device)

        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nüîπ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")
        lr_scheduler.step()

    print("\n‚úÖ **Training Completed** ‚úÖ")

# ‚úÖ Í≤ÄÏ¶ù Î£®ÌîÑ
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# ‚úÖ ÌÖåÏä§Ìä∏ Î£®ÌîÑ
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": np.mean(srocc_values),
        "plcc": np.mean(plcc_values)
    }

# ‚úÖ Î©îÏù∏ Ïã§Ìñâ
def main():
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    dataset_path = Path(args.data_base_path)
    dataset = KADID10KDataset(str(dataset_path), crop_size=224)

    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])
    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    model = EnhancedDistortionDetectionModel().to(device)
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # ‚úÖ Feature Map & Grad-CAM ÏãúÍ∞ÅÌôî
    visualize_feature_maps(model, val_dataloader, device)
    gradcam = GradCAM(model, model.vgg.conv5_3)
    for i, batch in enumerate(val_dataloader):
        img_A = batch["img_A"].to(device)
        cam = gradcam.generate_cam(img_A)
        gradcam.visualize_cam(img_A[0].cpu().numpy().transpose(1, 2, 0), cam, save_path=f"results/gradcam_{i}.png")
        if i == 5:
            break

    train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)
    test_metrics = test(model, test_dataloader, device)
    print("üîπ **Final Test Metrics:** üîπ", test_metrics)

if __name__ == "__main__":
    main()
 """

# ÏãúÍ∞ÅÌôî2
""" import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
from scipy import stats
from models.attention_se import EnhancedDistortionDetectionModel
from data.dataset_koniq10k import KONIQ10KDataset
from utils.utils import load_config
from grad_cam import GradCAM
import os

# ‚úÖ ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ± (Í≤∞Í≥º Ï†ÄÏû•)
os.makedirs("results", exist_ok=True)

# ‚úÖ ÏÜêÏã§ Ìï®Ïàò (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# ‚úÖ SROCC Î∞è PLCC Í≥ÑÏÇ∞
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# ‚úÖ Î™®Îç∏ Ï†ÄÏû• Ìï®Ïàò
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)

# ‚úÖ Attention Map ÏãúÍ∞ÅÌôî
# ‚úÖ Attention Map ÏãúÍ∞ÅÌôî (ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ± Ï∂îÍ∞Ä)
def visualize_attention_maps(model, dataloader, device):
    model.eval()
    batch = next(iter(dataloader))
    img_A = batch["img_A"].to(device)

    with torch.no_grad():
        feat1, feat2, feat3, feat4, feat5 = model.vgg(img_A)

        # ‚úÖ CoordAttention Ï†ÅÏö© Ï†ÑÌõÑ ÎπÑÍµê
        low_feat_before = feat1
        low_feat_after = model.coord_attn(feat1) * feat1

        # ‚úÖ HNCA Ï†ÅÏö© Ï†ÑÌõÑ ÎπÑÍµê
        high_feat_before = model.cpfe(feat5)
        high_feat_after = model.hnca(high_feat_before)

    attention_maps = {
        "Low_feat_before_CoordAttn": low_feat_before,
        "Low_feat_after_CoordAttn": low_feat_after,
        "High_feat_before_HNCA": high_feat_before,
        "High_feat_after_HNCA": high_feat_after
    }

    # ‚úÖ Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ ÌôïÏù∏ Î∞è ÏÉùÏÑ±
    save_dir = "results"
    os.makedirs(save_dir, exist_ok=True)

    for name, fmap in attention_maps.items():
        fmap = fmap[0].cpu().numpy()
        fmap = np.mean(fmap, axis=0)  # Ï±ÑÎÑê ÌèâÍ∑†
        plt.imshow(fmap, cmap='jet')
        plt.axis('off')
        plt.title(name)
        plt.savefig(os.path.join(save_dir, f"{name}.png"))  # üî• Ï†ÄÏû• ÏúÑÏπò ÏßÄÏ†ï
        plt.close()


# ‚úÖ ÌïôÏäµ Î£®ÌîÑ
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()
            preds = model(img_A)

            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        val_srocc, val_plcc = validate(model, val_dataloader, device)

        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nüîπ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")
        lr_scheduler.step()

    print("\n‚úÖ **Training Completed** ‚úÖ")

# ‚úÖ Í≤ÄÏ¶ù Î£®ÌîÑ
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# ‚úÖ ÌÖåÏä§Ìä∏ Î£®ÌîÑ
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": np.mean(srocc_values),
        "plcc": np.mean(plcc_values)
    }

# ‚úÖ Î©îÏù∏ Ïã§Ìñâ
def main():
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    dataset_path = Path(args.data_base_path)
    dataset = KONIQ10KDataset(str(dataset_path), crop_size=224)

    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])
    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    model = EnhancedDistortionDetectionModel().to(device)
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # ‚úÖ Attention Map ÏãúÍ∞ÅÌôî Ïã§Ìñâ (ÎîîÎ†âÌÜ†Î¶¨ ÏûêÎèô ÏÉùÏÑ± Ìè¨Ìï®)
    visualize_attention_maps(model, val_dataloader, device)

    print("\n‚úÖ **Attention Map Visualization Completed** ‚úÖ\n")

if __name__ == "__main__":
    main() """


"""
CoordAttention Ï†ÅÏö© Ï†ÑÌõÑ ÎπÑÍµê (feat1)
HNCA Ï†ÅÏö© Ï†ÑÌõÑ ÎπÑÍµê (CPFE(feat5))
"""

# ÏãúÍ∞ÅÌôî3
""" import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import cv2
from pathlib import Path
from tqdm import tqdm
from scipy import stats
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config
from PIL import Image


# ‚úÖ ÌäπÏ†ï Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú
IMAGE_PATH = "E:/ARNIQA - SE - mix/ARNIQA/dataset/TID2013/distorted_images/i07_15_3.bmp"


# ‚úÖ ÏÜêÏã§ Ìï®Ïàò (MSE + Perceptual Loss)
def distortion_loss(pred, gt, distortion_type_pred, distortion_type_gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    distortion_class_loss = nn.CrossEntropyLoss()(distortion_type_pred, distortion_type_gt)  # Distortion Î∂ÑÎ•ò Loss Ï∂îÍ∞Ä
    return mse_loss + 0.1 * perceptual_loss + 0.5 * distortion_class_loss


# ‚úÖ SROCC Î∞è PLCC Í≥ÑÏÇ∞
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc


# ‚úÖ Î™®Îç∏ Ï†ÄÏû• Ìï®Ïàò
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)

 """
# ‚úÖ Attention Map Overlay ÏãúÍ∞ÅÌôî
""" import cv2
import numpy as np
import matplotlib.pyplot as plt

def overlay_attention_on_image(image, attention_map, save_path):

    # ‚úÖ Attention Map Ï†ïÍ∑úÌôî (0~1 Ïä§ÏºÄÏùº)
    attention_map = (attention_map - np.min(attention_map)) / (np.max(attention_map) - np.min(attention_map) + 1e-8)
    attention_map = np.uint8(attention_map * 255)  # 0~255 Î≥ÄÌôò

    # ‚úÖ Color Map Ï†ÅÏö© (Jet Ïª¨Îü¨Îßµ)
    heatmap = cv2.applyColorMap(attention_map, cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  # OpenCVÎäî BGRÏù¥Îùº RGBÎ°ú Î≥ÄÌôò

    # ‚úÖ ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î°ú Î¶¨ÏÇ¨Ïù¥Ï¶à
    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))  # (W, H) ÎßûÏ∂îÍ∏∞

    # ‚úÖ imageÍ∞Ä Grayscale (H, W)Ïùº Í≤ΩÏö∞ RGB Î≥ÄÌôò
    if len(image.shape) == 2 or image.shape[-1] != 3:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)

    # ‚úÖ Ï±ÑÎÑê Ïàò ÎßûÏ∂îÍ∏∞ (H, W, 3)
    if heatmap.shape != image.shape:
        print(f"üî• [Error] Shape Mismatch: image {image.shape}, heatmap {heatmap.shape}")
        return

    # ‚úÖ Ïù¥ÎØ∏ÏßÄÏôÄ Overlay
    overlayed_img = cv2.addWeighted(image, 0.5, heatmap, 0.5, 0)

    # ‚úÖ Ï†ÄÏû• Î∞è ÏãúÍ∞ÅÌôî
    plt.figure(figsize=(6, 6))
    plt.imshow(overlayed_img)
    plt.axis('off')
    plt.title(save_path.split("/")[-1])
    plt.savefig(save_path)
    plt.close()




# ‚úÖ ÌäπÏ†ï Ïù¥ÎØ∏ÏßÄÎ°ú Attention Map ÏãúÍ∞ÅÌôî
def visualize_attention_maps(model, device):
    model.eval()

    # ‚úÖ ÌäπÏ†ï Ïù¥ÎØ∏ÏßÄ Î°úÎìú
    img = Image.open(IMAGE_PATH).convert("RGB")
    img = img.resize((224, 224))
    img_np = np.array(img)

    img_tensor = torch.tensor(img_np, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device) / 255.0

    with torch.no_grad():
        feat1, feat2, feat3, feat4, feat5 = model.vgg(img_tensor)
        low_feat_before = feat1
        low_feat_after = model.coord_attn(feat1)
        high_feat_before = model.cpfe(feat5)
        high_feat_after = model.hnca(high_feat_before)

    attention_maps = {
        "Low_feat_before_CoordAttn": low_feat_before,
        "Low_feat_after_CoordAttn": low_feat_after,
        "High_feat_before_HNCA": high_feat_before,
        "High_feat_after_HNCA": high_feat_after
    }

    for name, fmap in attention_maps.items():
        fmap = fmap[0].cpu().numpy()
        fmap = np.mean(fmap, axis=0)

        overlay_attention_on_image(img_np, fmap, f"results/{name}.png")


# ‚úÖ ÌïôÏäµ Î£®ÌîÑ
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()
            preds = model(img_A)

            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        val_srocc, val_plcc = validate(model, val_dataloader, device)

        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nüîπ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")
        lr_scheduler.step()

    print("\n‚úÖ **Training Completed** ‚úÖ")


# ‚úÖ Í≤ÄÏ¶ù Î£®ÌîÑ
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)


# ‚úÖ ÌÖåÏä§Ìä∏ Î£®ÌîÑ
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": np.mean(srocc_values),
        "plcc": np.mean(plcc_values)
    }


# ‚úÖ Î©îÏù∏ Ïã§Ìñâ
def main():
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    model = EnhancedDistortionDetectionModel().to(device)

    # ‚úÖ ÌäπÏ†ï Ïù¥ÎØ∏ÏßÄÎ°ú Attention Map ÏãúÍ∞ÅÌôî
    visualize_attention_maps(model, device)


if __name__ == "__main__":
    main()
 """

# 3/6
""" import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_kadid10k import KADID10KDataset
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config

# ‚úÖ ÏÜêÏã§ Ìï®Ïàò (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# ‚úÖ SROCC Î∞è PLCC Í≥ÑÏÇ∞
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# ‚úÖ ÌïôÏäµ Î£®ÌîÑ
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # ‚úÖ Î™®Îç∏ ÏòàÏ∏°
            preds = model(img_A)

            # ‚úÖ ÏÜêÏã§ Ìï®Ïàò Í≥ÑÏÇ∞
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # ‚úÖ Í≤ÄÏ¶ù
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # ‚úÖ Î™®Îç∏ Ï†ÄÏû•
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nüîπ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")

        lr_scheduler.step()

    print("\n‚úÖ **Training Completed** ‚úÖ")

    return {
        "loss": train_losses,
        "srocc": val_srocc_values,
        "plcc": val_plcc_values
    }

# ‚úÖ Í≤ÄÏ¶ù Î£®ÌîÑ
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# ‚úÖ ÌÖåÏä§Ìä∏ Î£®ÌîÑ (Ï∂îÍ∞Ä)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": srocc_values,
        "plcc": plcc_values
    }

# ‚úÖ Î™®Îç∏ Ï†ÄÏû• Ìï®Ïàò
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)



# ‚úÖ Î©îÏù∏ Ïã§Ìñâ
if __name__ == "__main__":
    # ‚úÖ ÏÑ§Ï†ï ÌååÏùº Î°úÎìú
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # ‚úÖ GPU ÏÑ§Ï†ï
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    # ‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú
    dataset_path = Path(args.data_base_path)
    dataset = KADID10KDataset(str(dataset_path), crop_size=224)


    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    # ‚úÖ Î™®Îç∏ ÏÉùÏÑ±
    model = EnhancedDistortionDetectionModel().to(device)

    # ‚úÖ ÏòµÌã∞ÎßàÏù¥Ï†Ä Î∞è Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # ‚úÖ ÌïôÏäµ ÏãúÏûë
    train_metrics = train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)

    # ‚úÖ ÌÖåÏä§Ìä∏ ÏàòÌñâ
    test_metrics = test(model, test_dataloader, device)

    # ‚úÖ ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•
    print("\n‚úÖ **Training Completed** ‚úÖ\n")

    print("üîπ **Final Training Metrics:** üîπ")
    for epoch, (loss, srocc, plcc) in enumerate(zip(train_metrics["loss"], train_metrics["srocc"], train_metrics["plcc"])):
        print(f"üìå **Epoch {epoch+1}:** Loss: {loss:.6f}, SROCC: {srocc:.6f}, PLCC: {plcc:.6f}")

    print("\nüîπ **Final Validation Metrics:** üîπ", {
        "srocc": train_metrics["srocc"],
        "plcc": train_metrics["plcc"]
    })

    print("üîπ **Final Test Metrics:** üîπ", test_metrics)
 """

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_flive import FLIVEDataset
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config

# ‚úÖ ÏÜêÏã§ Ìï®Ïàò (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# ‚úÖ SROCC Î∞è PLCC Í≥ÑÏÇ∞
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# ‚úÖ ÌïôÏäµ Î£®ÌîÑ
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # ‚úÖ Î™®Îç∏ ÏòàÏ∏°
            preds = model(img_A)

            # ‚úÖ ÏÜêÏã§ Ìï®Ïàò Í≥ÑÏÇ∞
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # ‚úÖ Í≤ÄÏ¶ù
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # ‚úÖ Î™®Îç∏ Ï†ÄÏû•
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nüîπ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")

        lr_scheduler.step()

    print("\n‚úÖ **Training Completed** ‚úÖ")

    return {
        "loss": train_losses,
        "srocc": val_srocc_values,
        "plcc": val_plcc_values
    }

# ‚úÖ Í≤ÄÏ¶ù Î£®ÌîÑ
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# ‚úÖ ÌÖåÏä§Ìä∏ Î£®ÌîÑ (Ï∂îÍ∞Ä)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": srocc_values,
        "plcc": plcc_values
    }

# ‚úÖ Î™®Îç∏ Ï†ÄÏû• Ìï®Ïàò
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)



# ‚úÖ Î©îÏù∏ Ïã§Ìñâ
if __name__ == "__main__":
    # ‚úÖ ÏÑ§Ï†ï ÌååÏùº Î°úÎìú
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # ‚úÖ GPU ÏÑ§Ï†ï
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    # ‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú
    dataset_path = Path(args.data_base_path)
    dataset = FLIVEDataset(str(dataset_path), crop_size=224)


    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    # ‚úÖ Î™®Îç∏ ÏÉùÏÑ±
    model = EnhancedDistortionDetectionModel().to(device)

    # ‚úÖ ÏòµÌã∞ÎßàÏù¥Ï†Ä Î∞è Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # ‚úÖ ÌïôÏäµ ÏãúÏûë
    train_metrics = train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)

    # ‚úÖ ÌÖåÏä§Ìä∏ ÏàòÌñâ
    test_metrics = test(model, test_dataloader, device)

    # ‚úÖ ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•
    print("\n‚úÖ **Training Completed** ‚úÖ\n")

    print("üîπ **Final Training Metrics:** üîπ")
    for epoch, (loss, srocc, plcc) in enumerate(zip(train_metrics["loss"], train_metrics["srocc"], train_metrics["plcc"])):
        print(f"üìå **Epoch {epoch+1}:** Loss: {loss:.6f}, SROCC: {srocc:.6f}, PLCC: {plcc:.6f}")

    print("\nüîπ **Final Validation Metrics:** üîπ", {
        "srocc": train_metrics["srocc"],
        "plcc": train_metrics["plcc"]
    })

    print("üîπ **Final Test Metrics:** üîπ", test_metrics)

