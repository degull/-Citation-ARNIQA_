# ì›ë³¸
""" 
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_spaq import SPAQDataset
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config

# âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# âœ… SROCC ë° PLCC ê³„ì‚°
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# âœ… í•™ìŠµ ë£¨í”„
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # âœ… ëª¨ë¸ ì˜ˆì¸¡
            preds = model(img_A)

            # âœ… ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # âœ… ê²€ì¦
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # âœ… ëª¨ë¸ ì €ì¥
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nğŸ”¹ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")

        lr_scheduler.step()

    print("\nâœ… **Training Completed** âœ…")

    return {
        "loss": train_losses,
        "srocc": val_srocc_values,
        "plcc": val_plcc_values
    }

# âœ… ê²€ì¦ ë£¨í”„
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# âœ… í…ŒìŠ¤íŠ¸ ë£¨í”„ (ì¶”ê°€)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": srocc_values,
        "plcc": plcc_values
    }

# âœ… ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)



# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    # âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # âœ… GPU ì„¤ì •
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    # âœ… ë°ì´í„°ì…‹ ë¡œë“œ
    dataset_path = Path(args.data_base_path)
    dataset = SPAQDataset(str(dataset_path), crop_size=224)


    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    # âœ… ëª¨ë¸ ìƒì„±
    model = EnhancedDistortionDetectionModel().to(device)

    # âœ… ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # âœ… í•™ìŠµ ì‹œì‘
    train_metrics = train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)

    # âœ… í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    test_metrics = test(model, test_dataloader, device)

    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\nâœ… **Training Completed** âœ…\n")

    print("ğŸ”¹ **Final Training Metrics:** ğŸ”¹")
    for epoch, (loss, srocc, plcc) in enumerate(zip(train_metrics["loss"], train_metrics["srocc"], train_metrics["plcc"])):
        print(f"ğŸ“Œ **Epoch {epoch+1}:** Loss: {loss:.6f}, SROCC: {srocc:.6f}, PLCC: {plcc:.6f}")

    print("\nğŸ”¹ **Final Validation Metrics:** ğŸ”¹", {
        "srocc": train_metrics["srocc"],
        "plcc": train_metrics["plcc"]
    })

    print("ğŸ”¹ **Final Test Metrics:** ğŸ”¹", test_metrics)
 """

# hmm
""" 
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_clive import CLIVEDataset
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config


# âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss


# âœ… SROCC ë° PLCC ê³„ì‚°
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc


# âœ… í…ŒìŠ¤íŠ¸ ë£¨í”„ (ì—í¬í¬ë³„ë¡œ SROCC, PLCC ì €ì¥)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)


# âœ… í•™ìŠµ ë£¨í”„ (ê° epoch í›„ test() ì‹¤í–‰)
def train(args, model, train_dataloader, val_dataloader, test_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []
    test_srocc_values, test_plcc_values = [], []  # âœ… Test ê²°ê³¼ ì €ì¥

    for epoch in range(args["training"]["epochs"]):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args['training']['epochs']}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # âœ… ëª¨ë¸ ì˜ˆì¸¡
            preds = model(img_A)

            # âœ… ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # âœ… ê²€ì¦
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # âœ… í…ŒìŠ¤íŠ¸ (ê° epoch í›„ ì‹¤í–‰)
        test_srocc, test_plcc = test(model, test_dataloader, device)
        test_srocc_values.append(test_srocc)
        test_plcc_values.append(test_plcc)

        # âœ… ëª¨ë¸ ì €ì¥
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args["checkpoint_base_path"], epoch, val_srocc)

        print(f"\nğŸ”¹ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}, "
              f"Test SROCC: {test_srocc:.6f}, Test PLCC: {test_plcc:.6f}")

        lr_scheduler.step()

    print("\nâœ… **Training Completed** âœ…")

    return {
        "loss": train_losses,
        "val_srocc": val_srocc_values,
        "val_plcc": val_plcc_values,
        "test_srocc": test_srocc_values,  # âœ… Test ê²°ê³¼ ì¶”ê°€ ì €ì¥
        "test_plcc": test_plcc_values
    }




# âœ… ê²€ì¦ ë£¨í”„
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)


# âœ… ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)


# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    # âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # âœ… GPU ì„¤ì •
    device = torch.device(f"cuda:{args['device']}" if torch.cuda.is_available() else "cpu")

    # âœ… ë°ì´í„°ì…‹ ë¡œë“œ
    dataset_path = Path(args["data_base_path"])
    dataset = CLIVEDataset(str(dataset_path), crop_size=224)

    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args["training"]["batch_size"], shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args["training"]["batch_size"], shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args["training"]["batch_size"], shuffle=False, num_workers=4)

    # âœ… ëª¨ë¸ ìƒì„±
    model = EnhancedDistortionDetectionModel().to(device)

    # âœ… ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    optimizer = optim.SGD(model.parameters(), lr=args["training"]["learning_rate"], momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # âœ… í•™ìŠµ ì‹œì‘
    train_metrics = train(args, model, train_dataloader, val_dataloader, test_dataloader, optimizer, lr_scheduler, device)

    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\nâœ… **Training Completed** âœ…\n")

    print("ğŸ”¹ **Final Training Metrics:** ğŸ”¹")
    for epoch, (loss, val_srocc, val_plcc, test_srocc, test_plcc) in enumerate(
            zip(train_metrics["loss"], train_metrics["val_srocc"], train_metrics["val_plcc"], train_metrics["test_srocc"], train_metrics["test_plcc"])):
        print(f"ğŸ“Œ **Epoch {epoch+1}:** Loss: {loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}, "
              f"Test SROCC: {test_srocc:.6f}, Test PLCC: {test_plcc:.6f}")

    print("\nğŸ”¹ **Final Validation Metrics:** ğŸ”¹", {
        "srocc": train_metrics["val_srocc"],
        "plcc": train_metrics["val_plcc"]
    })

    print("\nğŸ”¹ **Final Test Metrics:** ğŸ”¹", {
        "srocc": train_metrics["test_srocc"],
        "plcc": train_metrics["test_plcc"]
    })

 """

# HAN_IQA_PLUS
""" import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_koniq10k import KONIQ10KDataset
from models.attention_se import HAN_IQA_PLUS  # ğŸ”¥ ëª¨ë¸ ë³€ê²½
from utils.utils import load_config

# âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))  # L1 Loss
    return mse_loss + 0.1 * perceptual_loss  # ğŸ”¥ Perceptual Loss ë°˜ì˜

# âœ… SROCC ë° PLCC ê³„ì‚°
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# âœ… í•™ìŠµ ë£¨í”„
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # âœ… ëª¨ë¸ ì˜ˆì¸¡
            preds = model(img_A)

            # âœ… ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # âœ… ê²€ì¦
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # âœ… ëª¨ë¸ ì €ì¥
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nğŸ”¹ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")

        lr_scheduler.step()

    print("\nâœ… **Training Completed** âœ…")

    return {
        "loss": train_losses,
        "srocc": val_srocc_values,
        "plcc": val_plcc_values
    }

# âœ… ê²€ì¦ ë£¨í”„
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# âœ… í…ŒìŠ¤íŠ¸ ë£¨í”„ (ì¶”ê°€)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": srocc_values,
        "plcc": plcc_values
    }

# âœ… ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)

# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    # âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # âœ… GPU ì„¤ì •
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    # âœ… ë°ì´í„°ì…‹ ë¡œë“œ
    dataset_path = Path(args.data_base_path)
    dataset = KONIQ10KDataset(str(dataset_path), crop_size=224)

    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    # âœ… ëª¨ë¸ ìƒì„±
    model = HAN_IQA_PLUS().to(device)  # ğŸ”¥ ìƒˆë¡œìš´ ëª¨ë¸ ì ìš©

    # âœ… ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # âœ… í•™ìŠµ ì‹œì‘
    train_metrics = train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)

    # âœ… í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    test_metrics = test(model, test_dataloader, device)

    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\nâœ… **Training Completed** âœ…\n")

    print("ğŸ”¹ **Final Training Metrics:** ğŸ”¹")
    for epoch, (loss, srocc, plcc) in enumerate(zip(train_metrics["loss"], train_metrics["srocc"], train_metrics["plcc"])):
        print(f"ğŸ“Œ **Epoch {epoch+1}:** Loss: {loss:.6f}, SROCC: {srocc:.6f}, PLCC: {plcc:.6f}")

    print("\nğŸ”¹ **Final Validation Metrics:** ğŸ”¹", {
        "srocc": train_metrics["srocc"],
        "plcc": train_metrics["plcc"]
    })

    print("ğŸ”¹ **Final Test Metrics:** ğŸ”¹", test_metrics) """





# ì‹œê°í™”1
""" import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
from scipy import stats
from models.attention_se import EnhancedDistortionDetectionModel
from data.dataset_kadid10k import KADID10KDataset
from utils.utils import load_config
from grad_cam import GradCAM

# âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# âœ… SROCC ë° PLCC ê³„ì‚°
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# âœ… ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)

# âœ… Feature Map ì‹œê°í™”
def visualize_feature_maps(model, dataloader, device):
    model.eval()
    batch = next(iter(dataloader))
    img_A = batch["img_A"].to(device)

    with torch.no_grad():
        feat1, feat2, feat3, feat4, feat5 = model.vgg(img_A)
        cpfe_output = model.cpfe(feat5)
        hnca_output = model.hnca(cpfe_output)

    feature_maps = {
        "VGG_feat1": feat1,
        "VGG_feat2": feat2,
        "VGG_feat3": feat3,
        "VGG_feat4": feat4,
        "VGG_feat5": feat5,
        "CPFE_output": cpfe_output,
        "HNCA_output": hnca_output
    }

    for name, fmap in feature_maps.items():
        fmap = fmap[0].cpu().numpy()
        fmap = np.mean(fmap, axis=0)  # ì±„ë„ í‰ê· 
        plt.imshow(fmap, cmap='jet')
        plt.axis('off')
        plt.title(name)
        plt.savefig(f"results/{name}.png")
        plt.close()

# âœ… í•™ìŠµ ë£¨í”„
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()
            preds = model(img_A)

            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        val_srocc, val_plcc = validate(model, val_dataloader, device)

        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nğŸ”¹ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")
        lr_scheduler.step()

    print("\nâœ… **Training Completed** âœ…")

# âœ… ê²€ì¦ ë£¨í”„
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# âœ… í…ŒìŠ¤íŠ¸ ë£¨í”„
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": np.mean(srocc_values),
        "plcc": np.mean(plcc_values)
    }

# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    dataset_path = Path(args.data_base_path)
    dataset = KADID10KDataset(str(dataset_path), crop_size=224)

    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])
    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    model = EnhancedDistortionDetectionModel().to(device)
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # âœ… Feature Map & Grad-CAM ì‹œê°í™”
    visualize_feature_maps(model, val_dataloader, device)
    gradcam = GradCAM(model, model.vgg.conv5_3)
    for i, batch in enumerate(val_dataloader):
        img_A = batch["img_A"].to(device)
        cam = gradcam.generate_cam(img_A)
        gradcam.visualize_cam(img_A[0].cpu().numpy().transpose(1, 2, 0), cam, save_path=f"results/gradcam_{i}.png")
        if i == 5:
            break

    train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)
    test_metrics = test(model, test_dataloader, device)
    print("ğŸ”¹ **Final Test Metrics:** ğŸ”¹", test_metrics)

if __name__ == "__main__":
    main()
 """

# ì‹œê°í™”2
""" import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
from scipy import stats
from models.attention_se import EnhancedDistortionDetectionModel
from data.dataset_koniq10k import KONIQ10KDataset
from utils.utils import load_config
from grad_cam import GradCAM
import os

# âœ… ë””ë ‰í† ë¦¬ ìƒì„± (ê²°ê³¼ ì €ì¥)
os.makedirs("results", exist_ok=True)

# âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# âœ… SROCC ë° PLCC ê³„ì‚°
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# âœ… ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)

# âœ… Attention Map ì‹œê°í™”
# âœ… Attention Map ì‹œê°í™” (ë””ë ‰í† ë¦¬ ìƒì„± ì¶”ê°€)
def visualize_attention_maps(model, dataloader, device):
    model.eval()
    batch = next(iter(dataloader))
    img_A = batch["img_A"].to(device)

    with torch.no_grad():
        feat1, feat2, feat3, feat4, feat5 = model.vgg(img_A)

        # âœ… CoordAttention ì ìš© ì „í›„ ë¹„êµ
        low_feat_before = feat1
        low_feat_after = model.coord_attn(feat1) * feat1

        # âœ… HNCA ì ìš© ì „í›„ ë¹„êµ
        high_feat_before = model.cpfe(feat5)
        high_feat_after = model.hnca(high_feat_before)

    attention_maps = {
        "Low_feat_before_CoordAttn": low_feat_before,
        "Low_feat_after_CoordAttn": low_feat_after,
        "High_feat_before_HNCA": high_feat_before,
        "High_feat_after_HNCA": high_feat_after
    }

    # âœ… ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
    save_dir = "results"
    os.makedirs(save_dir, exist_ok=True)

    for name, fmap in attention_maps.items():
        fmap = fmap[0].cpu().numpy()
        fmap = np.mean(fmap, axis=0)  # ì±„ë„ í‰ê· 
        plt.imshow(fmap, cmap='jet')
        plt.axis('off')
        plt.title(name)
        plt.savefig(os.path.join(save_dir, f"{name}.png"))  # ğŸ”¥ ì €ì¥ ìœ„ì¹˜ ì§€ì •
        plt.close()


# âœ… í•™ìŠµ ë£¨í”„
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()
            preds = model(img_A)

            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        val_srocc, val_plcc = validate(model, val_dataloader, device)

        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nğŸ”¹ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")
        lr_scheduler.step()

    print("\nâœ… **Training Completed** âœ…")

# âœ… ê²€ì¦ ë£¨í”„
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# âœ… í…ŒìŠ¤íŠ¸ ë£¨í”„
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": np.mean(srocc_values),
        "plcc": np.mean(plcc_values)
    }

# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    dataset_path = Path(args.data_base_path)
    dataset = KONIQ10KDataset(str(dataset_path), crop_size=224)

    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])
    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    model = EnhancedDistortionDetectionModel().to(device)
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # âœ… Attention Map ì‹œê°í™” ì‹¤í–‰ (ë””ë ‰í† ë¦¬ ìë™ ìƒì„± í¬í•¨)
    visualize_attention_maps(model, val_dataloader, device)

    print("\nâœ… **Attention Map Visualization Completed** âœ…\n")

if __name__ == "__main__":
    main() """


"""
CoordAttention ì ìš© ì „í›„ ë¹„êµ (feat1)
HNCA ì ìš© ì „í›„ ë¹„êµ (CPFE(feat5))
"""

# ì‹œê°í™”3
""" import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import cv2
from pathlib import Path
from tqdm import tqdm
from scipy import stats
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config
from PIL import Image


# âœ… íŠ¹ì • ì´ë¯¸ì§€ ê²½ë¡œ
IMAGE_PATH = "E:/ARNIQA - SE - mix/ARNIQA/dataset/TID2013/distorted_images/i07_15_3.bmp"


# âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE + Perceptual Loss)
def distortion_loss(pred, gt, distortion_type_pred, distortion_type_gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    distortion_class_loss = nn.CrossEntropyLoss()(distortion_type_pred, distortion_type_gt)  # Distortion ë¶„ë¥˜ Loss ì¶”ê°€
    return mse_loss + 0.1 * perceptual_loss + 0.5 * distortion_class_loss


# âœ… SROCC ë° PLCC ê³„ì‚°
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc


# âœ… ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)

 """
# âœ… Attention Map Overlay ì‹œê°í™”
""" import cv2
import numpy as np
import matplotlib.pyplot as plt

def overlay_attention_on_image(image, attention_map, save_path):

    # âœ… Attention Map ì •ê·œí™” (0~1 ìŠ¤ì¼€ì¼)
    attention_map = (attention_map - np.min(attention_map)) / (np.max(attention_map) - np.min(attention_map) + 1e-8)
    attention_map = np.uint8(attention_map * 255)  # 0~255 ë³€í™˜

    # âœ… Color Map ì ìš© (Jet ì»¬ëŸ¬ë§µ)
    heatmap = cv2.applyColorMap(attention_map, cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  # OpenCVëŠ” BGRì´ë¼ RGBë¡œ ë³€í™˜

    # âœ… ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))  # (W, H) ë§ì¶”ê¸°

    # âœ… imageê°€ Grayscale (H, W)ì¼ ê²½ìš° RGB ë³€í™˜
    if len(image.shape) == 2 or image.shape[-1] != 3:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)

    # âœ… ì±„ë„ ìˆ˜ ë§ì¶”ê¸° (H, W, 3)
    if heatmap.shape != image.shape:
        print(f"ğŸ”¥ [Error] Shape Mismatch: image {image.shape}, heatmap {heatmap.shape}")
        return

    # âœ… ì´ë¯¸ì§€ì™€ Overlay
    overlayed_img = cv2.addWeighted(image, 0.5, heatmap, 0.5, 0)

    # âœ… ì €ì¥ ë° ì‹œê°í™”
    plt.figure(figsize=(6, 6))
    plt.imshow(overlayed_img)
    plt.axis('off')
    plt.title(save_path.split("/")[-1])
    plt.savefig(save_path)
    plt.close()




# âœ… íŠ¹ì • ì´ë¯¸ì§€ë¡œ Attention Map ì‹œê°í™”
def visualize_attention_maps(model, device):
    model.eval()

    # âœ… íŠ¹ì • ì´ë¯¸ì§€ ë¡œë“œ
    img = Image.open(IMAGE_PATH).convert("RGB")
    img = img.resize((224, 224))
    img_np = np.array(img)

    img_tensor = torch.tensor(img_np, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device) / 255.0

    with torch.no_grad():
        feat1, feat2, feat3, feat4, feat5 = model.vgg(img_tensor)
        low_feat_before = feat1
        low_feat_after = model.coord_attn(feat1)
        high_feat_before = model.cpfe(feat5)
        high_feat_after = model.hnca(high_feat_before)

    attention_maps = {
        "Low_feat_before_CoordAttn": low_feat_before,
        "Low_feat_after_CoordAttn": low_feat_after,
        "High_feat_before_HNCA": high_feat_before,
        "High_feat_after_HNCA": high_feat_after
    }

    for name, fmap in attention_maps.items():
        fmap = fmap[0].cpu().numpy()
        fmap = np.mean(fmap, axis=0)

        overlay_attention_on_image(img_np, fmap, f"results/{name}.png")


# âœ… í•™ìŠµ ë£¨í”„
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()
            preds = model(img_A)

            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        val_srocc, val_plcc = validate(model, val_dataloader, device)

        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nğŸ”¹ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")
        lr_scheduler.step()

    print("\nâœ… **Training Completed** âœ…")


# âœ… ê²€ì¦ ë£¨í”„
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)


# âœ… í…ŒìŠ¤íŠ¸ ë£¨í”„
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": np.mean(srocc_values),
        "plcc": np.mean(plcc_values)
    }


# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    model = EnhancedDistortionDetectionModel().to(device)

    # âœ… íŠ¹ì • ì´ë¯¸ì§€ë¡œ Attention Map ì‹œê°í™”
    visualize_attention_maps(model, device)


if __name__ == "__main__":
    main()
 """

# 3/6
""" import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_kadid10k import KADID10KDataset
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config

# âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# âœ… SROCC ë° PLCC ê³„ì‚°
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# âœ… í•™ìŠµ ë£¨í”„
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # âœ… ëª¨ë¸ ì˜ˆì¸¡
            preds = model(img_A)

            # âœ… ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # âœ… ê²€ì¦
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # âœ… ëª¨ë¸ ì €ì¥
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nğŸ”¹ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")

        lr_scheduler.step()

    print("\nâœ… **Training Completed** âœ…")

    return {
        "loss": train_losses,
        "srocc": val_srocc_values,
        "plcc": val_plcc_values
    }

# âœ… ê²€ì¦ ë£¨í”„
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# âœ… í…ŒìŠ¤íŠ¸ ë£¨í”„ (ì¶”ê°€)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": srocc_values,
        "plcc": plcc_values
    }

# âœ… ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)



# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    # âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # âœ… GPU ì„¤ì •
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    # âœ… ë°ì´í„°ì…‹ ë¡œë“œ
    dataset_path = Path(args.data_base_path)
    dataset = KADID10KDataset(str(dataset_path), crop_size=224)


    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    # âœ… ëª¨ë¸ ìƒì„±
    model = EnhancedDistortionDetectionModel().to(device)

    # âœ… ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # âœ… í•™ìŠµ ì‹œì‘
    train_metrics = train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)

    # âœ… í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    test_metrics = test(model, test_dataloader, device)

    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\nâœ… **Training Completed** âœ…\n")

    print("ğŸ”¹ **Final Training Metrics:** ğŸ”¹")
    for epoch, (loss, srocc, plcc) in enumerate(zip(train_metrics["loss"], train_metrics["srocc"], train_metrics["plcc"])):
        print(f"ğŸ“Œ **Epoch {epoch+1}:** Loss: {loss:.6f}, SROCC: {srocc:.6f}, PLCC: {plcc:.6f}")

    print("\nğŸ”¹ **Final Validation Metrics:** ğŸ”¹", {
        "srocc": train_metrics["srocc"],
        "plcc": train_metrics["plcc"]
    })

    print("ğŸ”¹ **Final Test Metrics:** ğŸ”¹", test_metrics)
 """

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
from tqdm import tqdm
from pathlib import Path
from scipy import stats
from data.dataset_flive import FLIVEDataset
from models.attention_se import EnhancedDistortionDetectionModel
from utils.utils import load_config

# âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE + Perceptual Loss)
def distortion_loss(pred, gt):
    mse_loss = nn.MSELoss()(pred, gt)
    perceptual_loss = torch.mean(torch.abs(pred - gt))
    return mse_loss + 0.1 * perceptual_loss

# âœ… SROCC ë° PLCC ê³„ì‚°
def calculate_srcc_plcc(preds, targets):
    preds, targets = preds.cpu().numpy(), targets.cpu().numpy()
    srocc, _ = stats.spearmanr(preds.flatten(), targets.flatten())
    plcc, _ = stats.pearsonr(preds.flatten(), targets.flatten())
    return srocc, plcc

# âœ… í•™ìŠµ ë£¨í”„
def train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device):
    best_srocc = -1
    model.train()

    train_losses = []
    val_srocc_values, val_plcc_values = [], []

    for epoch in range(args.training.epochs):
        running_loss = 0.0
        progress_bar = tqdm(train_dataloader, desc=f"Epoch [{epoch + 1}/{args.training.epochs}]")

        for batch in progress_bar:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            optimizer.zero_grad()

            # âœ… ëª¨ë¸ ì˜ˆì¸¡
            preds = model(img_A)

            # âœ… ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°
            loss = distortion_loss(preds, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix(loss=running_loss / (len(progress_bar) + 1))

        avg_loss = running_loss / len(train_dataloader)
        train_losses.append(avg_loss)

        # âœ… ê²€ì¦
        val_srocc, val_plcc = validate(model, val_dataloader, device)
        val_srocc_values.append(val_srocc)
        val_plcc_values.append(val_plcc)

        # âœ… ëª¨ë¸ ì €ì¥
        if val_srocc > best_srocc:
            best_srocc = val_srocc
            save_checkpoint(model, args.checkpoint_base_path, epoch, val_srocc)

        print(f"\nğŸ”¹ Epoch {epoch+1}: Loss: {avg_loss:.6f}, Val SROCC: {val_srocc:.6f}, Val PLCC: {val_plcc:.6f}")

        lr_scheduler.step()

    print("\nâœ… **Training Completed** âœ…")

    return {
        "loss": train_losses,
        "srocc": val_srocc_values,
        "plcc": val_plcc_values
    }

# âœ… ê²€ì¦ ë£¨í”„
def validate(model, dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return np.mean(srocc_values), np.mean(plcc_values)

# âœ… í…ŒìŠ¤íŠ¸ ë£¨í”„ (ì¶”ê°€)
def test(model, test_dataloader, device):
    model.eval()
    srocc_values, plcc_values = [], []

    with torch.no_grad():
        for batch in test_dataloader:
            img_A = batch["img_A"].to(device)
            targets = batch["mos"].to(device)

            preds = model(img_A)
            srocc, plcc = calculate_srcc_plcc(preds, targets)

            srocc_values.append(srocc)
            plcc_values.append(plcc)

    return {
        "srocc": srocc_values,
        "plcc": plcc_values
    }

# âœ… ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_checkpoint(model, checkpoint_path, epoch, srocc):
    filename = f"epoch_{epoch}_srocc_{srocc:.3f}.pth"
    torch.save(model.state_dict(), Path(checkpoint_path) / filename)



# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    # âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ
    config_path = "E:/ARNIQA - SE - mix/ARNIQA/config.yaml"
    args = load_config(config_path)

    # âœ… GPU ì„¤ì •
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")

    # âœ… ë°ì´í„°ì…‹ ë¡œë“œ
    dataset_path = Path(args.data_base_path)
    dataset = FLIVEDataset(str(dataset_path), crop_size=224)


    train_size = int(0.7 * len(dataset))
    val_size = int(0.1 * len(dataset))
    test_size = len(dataset) - train_size - val_size

    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

    train_dataloader = DataLoader(train_dataset, batch_size=args.training.batch_size, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)
    test_dataloader = DataLoader(test_dataset, batch_size=args.training.batch_size, shuffle=False, num_workers=4)

    # âœ… ëª¨ë¸ ìƒì„±
    model = EnhancedDistortionDetectionModel().to(device)

    # âœ… ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    optimizer = optim.SGD(model.parameters(), lr=args.training.learning_rate, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)

    # âœ… í•™ìŠµ ì‹œì‘
    train_metrics = train(args, model, train_dataloader, val_dataloader, optimizer, lr_scheduler, device)

    # âœ… í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    test_metrics = test(model, test_dataloader, device)

    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\nâœ… **Training Completed** âœ…\n")

    print("ğŸ”¹ **Final Training Metrics:** ğŸ”¹")
    for epoch, (loss, srocc, plcc) in enumerate(zip(train_metrics["loss"], train_metrics["srocc"], train_metrics["plcc"])):
        print(f"ğŸ“Œ **Epoch {epoch+1}:** Loss: {loss:.6f}, SROCC: {srocc:.6f}, PLCC: {plcc:.6f}")

    print("\nğŸ”¹ **Final Validation Metrics:** ğŸ”¹", {
        "srocc": train_metrics["srocc"],
        "plcc": train_metrics["plcc"]
    })

    print("ğŸ”¹ **Final Test Metrics:** ğŸ”¹", test_metrics)

